# 线程池

## 1.并发和并行

**相同点**

- CPU执行多个任务的方式
- 给人宏观的感受就是程序一起执行	

**不同点**

- 并发的多个任务之间是互相抢占资源的
- 并行的多个任务之间是不互相抢占资源的

### 并发

- 在操作系统中，一个时间段中有多个进程都处于已启动运行到运行完毕之间的状态。但任一个时刻点上仍只有一个进程在运行
- 并发的实质上是宏观并行，微观串行
- 并发通过进程调度算法实现的
- 虽然 CPU 在同一时刻只能执行一个任务，但是通过将 CPU 的使用权在恰当的时机分配给不同的任务，使得多个任务在视觉上看起来是一起执行的。
- CPU 的执行速度极快，多任务切换的时间也极短。
- 并发是针对单核单cpu提出的，多核单cpu也能实现并行					

### 并行

- 并行是针对多核cpu提出的概念
- 和单核 CPU 不同，多个CPU 真正实现了同时执行多个任务

### 并发与并行的技术支持

- 资源分配（cpu资源，内存资源，外部设备资源，磁盘资源）
- 资源的分配原则：
  - 提高资源利用率；
  - 在合理的时间内使用所有用户都可以得到所需资源（不要出现饿死的情况）——公平；
  - 对独占资源实施互斥使用；
  - 防止因资源分配不当而引起的死锁；这些目标相互牵制，需要权衡。

- 常用资源分配策略：
  - 进程调度算法
  - 内存管理
  - 设备管理
  - 文件管理

- 其他技术
  - 英特尔超线程技术
  - 虚拟cpu



## 2.多线程优势

### 优势

- **单核**CPU/**多核**CPU下多线程适用于**IO密集型**任务
- **多核**CPU下适合**CPU密集型**任务，**单核**CPU情况下不适合**CPU密集型**任务

IO密集型任务：设备，文件，网络等操作(eg: 等待客户端的连接IO操作是可以把程序阻塞的)

CPU密集型任务：程序的指令都是用作计算的(从1加到100)



### 为什么单核CPU下多线程不适合CPU密集型任务

- 多线程共享CPU时间片，一个线程的时间片执行完需要进行线程上下文的切换

- 线程的上下文切换需要额外的开销
- 多线程存在上下文切换，是额外的花销，线程越多上下文切换所花费的额外时间也越多，倒不如一个线程一直进行计算。

线程上下文：上一个线程被暂停，下一个线程开始执行的过程。



### 线程栈(了解)

[浅谈Linux 中的进程栈、线程栈、内核栈、中断栈 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/188577062)



### 线程真的越多越好吗

- 线程创建和销毁的开销很大
  - 在linux中线程是共享地址空间的进程，只不过在创建是添加CLONE_VM标记
  - 在一些场景下实时创建和销毁线程导致CPU利用率降低**(使用线程池改善!!!)**
- 线程栈本身占用大量内存(ulimit -a查看，每一个线程默认栈空间8Mb)
  - 创建大量线程，每一个线程都需要线程栈，导致没有栈空间
- 线程的上下文切换需要占用大量时间
- 大量线程同时唤醒会使系统经常出现锯齿状负载或者瞬间高负载量使系统宕机
  - 同一时间很多IO操作准备完毕，此时大量线程从虚拟内存、磁盘中调入内存导致宕机



### 比较合适的线程数量

一般合适的线程数量于CPU核心数量相关，**一个核心对应一个线程**

众多优秀网络开源框架都是使用**线程池 + IO复用**技术, eg:

- C++ muduo、libevent
- Java Netty、mina



## 3.线程池

### 线程池优势

操作系统上创建线程和销毁线程都是很"重"的操作，耗时耗性能都比较多，那么在服务执行的过程中， 如果业务量比较大，实时的去创建线程、执行业务、业务完成后销毁线程，那么会导致系统的实时性能 降低，业务的处理能力也会降低。 线程池的优势就是（每个池都有自己的优势），在服务进程启动之初，就事先创建好线程池里面的线 程，当业务流量到来时需要分配线程，直接从线程池中获取一个空闲线程执行task任务即可，task执行 完成后，也不用释放线程，而是把线程归还到线程池中继续给后续的task提供服务。

总结：将线程存放在线程池中，而不是每次处理任务都创建线程，任务处理完销毁线程。每当出现新的任务，从线程池中取出一个空闲的线程，处理完任务再把线程放回线程池，避免频繁的创建与销毁线程。



线程池的模式（可以在设计时设置开关选择线程池模式）：

- **fixed模式线程池**：线程池里面的线程个数是固定不变的，一般是ThreadPool创建时根据当前机器的CPU核心数量进行指 定。
- **cached模式线程池**：线程池里面的线程个数是可动态增长的，根据任务的数量动态的增加线程的数量，但是会设置一个线程 数量的阈值（线程过多的坏处上面已经讲过了），任务处理完成，如果动态增长的线程空闲了60s还没 有处理其它任务，那么关闭线程，保持池中最初数量的线程即可。



## 4.线程同步

**线程同步的两种方式：**

- **线程互斥**
- **线程通信**



### 线程互斥

- **互斥锁**
- **atomic原子类型**

是否需要线程互斥主要看这段代码能不能在多线程环境下执行 <==> 这段代码是否存在**竟态条件**

**竟态条件**：这段代码在多线程环境下执行，随着线程调度顺序的不同而得到不同的结果，这段代码称为**临界区代码**，对临界区代码要保证其原子操作

临界区资源：线程之间可以共享的资源，例如堆区，数据区，代码区

互斥锁与atomic原子类型是本项目实现**线程安全**的两种主要方式



**互斥锁**

一次性需要操作多行代码使用互斥锁保证所有代码都是在线程安全下执行的，而不是只运行了几行代码就因为CPU时间片耗尽而导致线程的切换使得临界区代码一次性被多个线程执行。

互斥锁每次加锁与解锁效率比较低，只执行简单的代码时影响效率，因此使用atomic原子类型



**atomic原子类型**

atomic原子类型是一种轻量级的锁，适合处理简单的代码



atomic使用例证：

count++原理（汇编代码）

```cpp
count++;  // count = 1

/*
	* 此时两个线程thread1, thread2需要先后执行第一行代码，正常结果应该是count++被执行了两次
	* ++原理：
	mov eax, count  // 将count的值拷贝到eax寄存器中
	add eax, 1      // 对eax寄存器中的值+1
    mov count, eax  // 将eax寄存器中的值拷贝到count中
    * 此时第一个线程thread1只执行了前两行汇编指令，就因为CPU时间片耗尽而切换到第二个线程thread2，
    * 导致第一个线程thread1并没有将eax寄存器中的值成功拷贝回count中
    * 使得两个线程结束后count的值是2并不是3
    * 此时使用互斥锁可以解决上述问题，但是互斥锁并不适合此场景，因此使用更加轻量级的atomic原子类型
    * atomic原子类型使用方法待补充S
*/
```





### 线程通信

- 条件变量 condition_variable
- 信号量 semaphore



**条件变量 **

举例线程通信：

​																	thread1（线程1）																thread2（线程2）

​																			|																							|

​																			|																							|

​																			|																					    code2

​																			|																							|

​																		code1   																					|

​																			|																							|

​																			|																							|

上述为两个线程执行的时间片(**注意，我们无法得知线程的执行顺序，这与操作系统的线程调度算法有关**)，其中thread1中的代码片段code1执行需要thread2执行代码片段code2。这就涉及到了线程通信，这里使用**条件变量（condition_variable）** + **互斥锁（mutex）**实现。

如果thread1先执行，执行到代码片段code1时，会进入等待状态，而不是阻塞状态，等到内核调度thread2线程并执行code2时，可以通过信号量通知thread1(以及其他等待code2的线程)继续执行。此时thread1才能继续执行。



**生产者消费者模型**

![](https://img1.imgtp.com/2023/06/02/BXXeNh82.png)

## 5.项目代码

### 知识准备

1. 了解C++11 std::thread类模板
2. 了解C++11 std::bind()绑定器
3. 了解函数对象
4. 了解智能指针
5. 了解std::atomic_int原子类型
6. 了解std::mutex
7. 了解std::conditional_variable
8. 了解C++17的Any类型
9. 了解RTTI类型识别



## 6.Any类型

Any类型是任意的其他类型，C++17提供了Any类型。

### Any的实现

|       任意的其他类型       |   template   |
| :------------------------: | :----------: |
| 能让一个类型指向任意的类型 | 基类类型指针 |

```cpp
/* Any类型：表示可以接收任意数据的类型 */
class Any
{
public:
    /* 使用默认构造函数能够减少错误 */
    Any() = default;

    /* 因为使用了unique_ptr禁用左值引用的拷贝构造与赋值，在此禁用 */
    Any(const Any&) = delete;
    Any operator=(const Any&) = delete;

    /* 因为使用了unique_ptr保留了右值引用的赋值，在此默认使用 */
    Any(Any&&) = default;
    Any& operator=(Any&&) = default;

    /* 使用默认析构函数能够减少错误 */
    ~Any() = default;

    /* 这个构造函数可以让Any类型接收任意其他的数据来构造Any对象 */
    template<typename T>
    Any(T data) : base_(std::make_uniqueD<Derive<T>>(data))  // 构造Any对象时就让base_基类指针指向派生类对象发生多态，并传入数据
    {}

    /* 把Any对象里面存储的数据提取出来 */
    template<typename T>
    T cast_()
    {
        /* 通过base_找到他所指向的Derive对象，从中提取data_成员变量 */
        /* 基类指针需要转换成派生类指针，RTTI类型识别（强制类型转换） */
        /* get函数：返回智能指针中保存的裸指针。考虑到有些函数的参数需要内置的裸指针，所以引入该函数。 */
        Derive<T>* pd = dynamic_cast<Derive<T>*>(base_.get());  
        if (pd == nulptr)
        {
            throw "type is unmatch!";
        }
        return pd->data_;
    }

private:
    /* 基类类型 */
    class Base
    {
    public:
        virtual ~Base() = default;  // 虚析构，使用默认实现
    };

    /* 派生类类型，保存任意类型的数据，通过多态访问被保存的数据 */
    template<typename T>
    class Derive : Base
    {
    public:
        /* 将任意类型的数据保存在派生类中，并且发生多态时，需要传入这个任意类型的数据 */
        Derive(T data) : data_(data)
        {}
        T data_;  // 保存了任意的其他类型
    };

private:
    /* 
        * 定义一个基类指针用于多态访问任意类型数据
        * unique_ptr把左值引用的拷贝构造函数与赋值删除了，保留了右值引用的拷贝构造与赋值
    */
    std::unique_ptr<Base> base_;
};

```



## 7.信号量

**信号量与互斥锁的区别**

互斥锁的资源计数只有0与1，互斥锁被持有后从1变为0，释放后从0变为1；同一时刻只能有一个线程持有锁，释放锁也**只能被**持有锁的线程进行释放

信号量的资源计数可以被指定，当一个线程获取信号量，信号量资源计数-1(p操作)，反之+1(v操作)，一个线程获取信号量**可以被**另一个线程释放信号量

二元信号量与互斥锁相近，但是互斥锁只能被持有锁的线程释放，信号没有这方面的限制



```cpp
/* 实现一个信号量使用互斥锁与条件变量实现 */
class Semaphore
{
public:
    /* 构造函数，可以指定信号量资源计数 */
    Semaphore(int limit = 0) 
        : resLimit_(limit)
    {}

    /* 使用默认析构 */
    ~Semaphore() = default;

    /* 获取一个信号量资源 */ 
    void wait()
    {
        std::unique_lock<std::mutex>lock(mtx_);  // 获取一把锁
        /* 等待信号量有资源，没有资源进行阻塞 */
        cond_.wait(lock, [&]()->bool { return resLimit_ > 0; });
        resLimit_--;
    }

    /* 增加一个信号量资源 */ 
    void post()
    {
        std::unique_lock<std::mutex>lock(mtx_);  // 获取一把锁
        resLimit_++;  
        cond_.notify_all();  // 告知其他线程信号量+1
    }
    

private:
    int resLimit_;  // 资源计数
    std::mutex mtx_;  // 互斥锁
    std::condition_variable cond_;  // 条件变量 
};
```

